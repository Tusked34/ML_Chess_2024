{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_vector(fen):\n",
    "    board = chess.Board(fen)\n",
    "    vector = np.zeros(64)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            vector[square] = {\n",
    "                \"P\": 1, \"N\": 2, \"B\": 3, \"R\": 4, \"Q\": 5, \"K\": 6,\n",
    "                \"p\": -1, \"n\": -2, \"b\": -3, \"r\": -4, \"q\": -5, \"k\": -6\n",
    "            }[piece.symbol()]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données depuis un CSV\n",
    "def load_data(file_path, max_lines=None):\n",
    "    data = pd.read_csv(file_path)\n",
    "    if max_lines:\n",
    "        data = data.head(max_lines)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, row in data.iterrows():\n",
    "        try:\n",
    "            fen = row['fen']\n",
    "            best_move = row['analysed_best_move']\n",
    "            X.append((fen))\n",
    "            y.append((best_move))\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec la ligne {i}: {e}\")\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données à partir du fichier CSV\n",
    "file_path = 'data\\data_cleaned.csv'  # Remplacez par le chemin de votre fichier CSV\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extraire les colonnes 'fen' et 'best_move'\n",
    "X = data['fen']  # Variable explicative\n",
    "y = data['most_popular_move_of_the_category']  # Variable à expliquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_spbase' from 'scipy.sparse._base' (c:\\Users\\theol\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Diviser les données en ensembles d'entraînement et de validation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\theol\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py:73\u001b[0m\n\u001b[0;32m     68\u001b[0m if __SKLEARN_SETUP__:\n\u001b[0;32m     69\u001b[0m     sys.stderr.write(\"Partial import of sklearn during the build process.\\n\")\n\u001b[0;32m     70\u001b[0m     # We are not importing the rest of scikit-learn during the build\n\u001b[0;32m     71\u001b[0m     # process, as it may not be compiled yet\n\u001b[0;32m     72\u001b[0m else:\n\u001b[1;32m---> 73\u001b[0m     # `_distributor_init` allows distributors to run custom init code.\n\u001b[0;32m     74\u001b[0m     # For instance, for the Windows wheel, this is used to pre-load the\n\u001b[0;32m     75\u001b[0m     # vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\n\u001b[0;32m     76\u001b[0m     # sub-folder.\n\u001b[0;32m     77\u001b[0m     # It is necessary to do this prior to importing show_versions as the\n\u001b[0;32m     78\u001b[0m     # later is linked to the OpenMP runtime to make it possible to introspect\n\u001b[0;32m     79\u001b[0m     # it and importing it first would fail if the OpenMP dll cannot be found.\n\u001b[0;32m     80\u001b[0m     from . import (\n\u001b[0;32m     81\u001b[0m         __check_build,  # noqa: F401\n\u001b[0;32m     82\u001b[0m         _distributor_init,  # noqa: F401\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     84\u001b[0m     from .base import clone\n",
      "File \u001b[1;32mc:\\Users\\theol\\anaconda3\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32mc:\\Users\\theol\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:15\u001b[0m\n\u001b[0;32m     11\u001b[0m from ._chunking import gen_batches, gen_even_slices\n\u001b[0;32m     12\u001b[0m from ._estimator_html_repr import estimator_html_repr\n\u001b[0;32m     14\u001b[0m # Make _safe_indexing importable from here for backward compat as this particular\n\u001b[1;32m---> 15\u001b[0m # helper is considered semi-private and typically very useful for third-party\n\u001b[0;32m     16\u001b[0m # libraries that want to comply with scikit-learn's estimator API. In particular,\n\u001b[0;32m     17\u001b[0m # _safe_indexing was included in our public API documentation despite the leading\n\u001b[0;32m     18\u001b[0m # `_` in its name.\n\u001b[0;32m     19\u001b[0m from ._indexing import (\n\u001b[0;32m     20\u001b[0m     _safe_indexing,  # noqa\n\u001b[0;32m     21\u001b[0m     resample,\n\u001b[0;32m     22\u001b[0m     shuffle,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m from ._mask import safe_mask\n",
      "File \u001b[1;32mc:\\Users\\theol\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\theol\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\theol\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py:294\u001b[0m\n\u001b[0;32m    291\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# Filter PendingDeprecationWarning for np.matrix introduced with numpy 1.15\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m _warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe matrix subclass is not the recommended way\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PytestTester\n\u001b[0;32m    297\u001b[0m test \u001b[38;5;241m=\u001b[39m PytestTester(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\theol\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_csr.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0;32m     11\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast, get_index_dtype\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_spbase' from 'scipy.sparse._base' (c:\\Users\\theol\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py)"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le modèle\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, input_dim=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64 * 64, activation='softmax')  # Sortie pour 4096 mouvements possibles\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement\n",
    "history = model.fit(X, y, validation_split=0.2, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "model.save(\"chess_ai_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle\n",
    "model = tf.keras.models.load_model(\"chess_ai_model.h5\")\n",
    "\n",
    "# Tester une prédiction\n",
    "fen = \"1B1b4/8/2pP2p1/5p2/k7/8/5PK1/8 b - -\"\n",
    "fen_vector = fen_to_vector(fen)\n",
    "prediction = model.predict(np.array([fen_vector]))\n",
    "predicted_move_index = np.argmax(prediction)\n",
    "\n",
    "# Convertir l'indice en mouvement (par exemple, 0 -> 'a1a2')\n",
    "from_square = predicted_move_index // 64\n",
    "to_square = predicted_move_index % 64\n",
    "predicted_move = chess.SQUARE_NAMES[from_square] + chess.SQUARE_NAMES[to_square]\n",
    "\n",
    "print(f\"Mouvement prédit : {predicted_move}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
