{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliothèques utilisés : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import chess\n",
    "import random\n",
    "\n",
    "from Fct.fct_preprocess import *\n",
    "from Fct.fct_eval import *\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dropout, Dense, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **INTRODUCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'heure actuel, le monde des échecs professionnels connait une vrai crise : des parties de tournois majeurs pas retransmises direct live, scandale de triches, Magnus Carlsen viré en plein championnat du monde pour être venue en \"tenue non-conforme\" (un pantalon en jean...). Ces incidents ont pour conséquence une perte d'interet du public pour la FIDE (Fédération International D'Echecs) et pour le format de parti longue. Mais s'il y a bien une chose qui est sur une bonne dynamique dans les échecs, c'est bien l'IA. Cela fait bien des années que l'intelligence artificielle dépasse ce qui est phyiquement possible a faire pour l'humain dans ce domaine.\n",
    "\n",
    "Parmis tout les moteurs d'échecs ayant existés (Deep-Blue, etc...), le requin de cette catégorie, c'est Stockfish. C'est un moteur d'échecs open source créé en 2008 par Tord Romstad, Marco Costalba et Joona Kiiski. Développé et amélioré par une communauté active, il est rapidement devenu l’un des moteurs d’échecs les plus puissants au monde. Stockfish fonctionne en combinant des algorithmes de recherche avancés, comme l’élagage alpha-bêta et le Deep Iterative Deepening, avec une fonction d’évaluation capable d’analyser les positions selon divers critères : avantage matériel, structure des pions, sécurité du roi, etc. Depuis 2020, il intègre NNUE, un réseau de neurones optimisé pour les processeurs, qui améliore la précision de ses évaluations. Aujourd'hui, Stockfish est utilisé pour analyser des parties, entraîner des joueurs, organiser des tournois en ligne et développer des projets d’intelligence artificielle. Gratuit et open source, il est devenu incontournable pour les amateurs et professionnels des échecs.\n",
    "\n",
    "Pour en arrivé jusque la, Stockfish s'appuie dans la combinaisons de multitude d'algorithmes, de technologies, méthodes analyses et entrainement depuis plus de 15 ans. Le \"jeu des rois\" étant devenue le \"jeu des robots\", nous allons faire de même. Notre objectif dans ce projet, est alors de créer une l'IA joueuse d'échecla plus performante possible, à l'aide un réseaux de neurone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. CHOIX DU JEU DE DONNEES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une des meilleure source donee en terme d'echec est Lichess (abréviation de \"Libre Chess\"), vest une plateforme gratuite et open-source dédiée aux échecs en ligne. Elle permet aux joueurs de tous niveaux de jouer, apprendre et s'améliorer aux échecs via navigatuer web ou une application mobile. Plusieurs banques de données sont disponibles en libre accès sur leur site internet, parmis elles, deux sont de bonnes candidates pour notre sujet :\n",
    "- **Standars Chess** : Cette basse de donnée regroupe toutes les parties classées qui ont été joué sur lichess, chaque mois, depuis sa création, soit 6 298 645 464 parties standard.\n",
    "- **Evaluation\"** : 173 866 932 positions d'échecs différentes évaluées avec Stockfish. Produites par et pour le tableau d'analyse de Lichess, utilisant différentes versions de Stockfish dans les navigateurs des utilisateurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLABLABLA a completer et reecrire en ajoutant parargraphe sur l'IA : Grace a notre reflexion personnelle et a l'avis de ChatGPT, nous avons vue que le choix de prendre les données \"Evaluation\" est notre meilleur choix : \n",
    "stockifsh est + fort que nimporte quel joueur donc meilleurs données + même parmis toutes les parties il faut prendre celles avec les top joueurs et même eux peuvent faire de la merde parfois donc pas 100 fiables. Stockfish que des positions différentes et plusieurs evaluations différentes pour chacune donc c'est hyper pertinent pas de données a jeter.\n",
    "\n",
    "Même si cela revient a utiliser une IA pour entrainer notre IA, Stockfish lui même s'appuyer sur le moteur \"Glaurung\", il vaut mieux mettre toute les chances de notre coté et prendre les meilleurs données a notre dispositon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier brut faisant 40 giga, n'est uploadable sur le git, mais il est dispnible en telechargement libre a l'adresse suivante : https://database.lichess.org/#evals \n",
    "Si vous souhaitez reproduire le traitement des données et l'entrainement des modèles via les fichiers du dossier **src**, il faut telecharger le fichier ci-dessus de le placer dans le dossier **data** sous le nom **\"lichess_db_eval.jsonl\"**\n",
    "\n",
    "*NB : les données de ce fichier varies légérements au file du temps car il est mis a jours tout les 1er du mois par Lichess. Celui que nous utilisons date du 1er decembre 2024.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. EXPLORATION ET TRAITEMENT DES DONNEES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier JSONL contenant les données originales contient 170M positions différentes, chacune avec plusieurs évaluations Stockfish. Nous limitons alors la taille la taille de notre future jeu de nos jeux de données en deux fichiers. Le premier est le plus petit, il contient 1 milions de de positions et le second est plus grand avec 10 millions positions. Cela permet de limiter le temps d'entrainements de nos modèles, ce dernier étant proportinnel a la taille des données d'entrainements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.A Chargement des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_path, max_rows=1000000):\n",
    "    \"\"\"\n",
    "    Extrait les données d'un fichier JSONL contenant des positions d'échecs et les évalue, \n",
    "    en créant un DataFrame à partir des informations extraites.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin du fichier contenant les données au format JSONL (une position par ligne).\n",
    "        max_rows (int, optional): Nombre maximal de lignes à lire dans le fichier. Par défaut, 1 000 000.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Un DataFrame contenant les colonnes suivantes :\n",
    "            - \"fen\" : Représentation FEN de l'échiquier.\n",
    "            - \"knodes\" : Nombre de nœuds évalués.\n",
    "            - \"depth\" : Profondeur de recherche de l'évaluation.\n",
    "            - \"cp\" : Centipawn score de l'évaluation (avantage positionnel en valeurs de pions).\n",
    "            - \"mate\" : Nombre de coups avant échec et mat (si applicable).\n",
    "            - \"line\" : Ligne de coups prévus.\n",
    "    \"\"\"\n",
    "    data = []  # Liste pour stocker les données extraites\n",
    "    \n",
    "    # Ouvre le fichier en lecture\n",
    "    with open(file_path, 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            # Arrête la lecture si le nombre maximal de lignes est atteint\n",
    "            if idx >= max_rows:\n",
    "                break\n",
    "\n",
    "            # Chargement de la ligne JSON en dictionnaire Python\n",
    "            position = json.loads(line)\n",
    "            fen = position.get(\"fen\")  # Extrait le code FEN\n",
    "            \n",
    "            # Parcoure les évaluations disponibles pour cette position\n",
    "            for eval_data in position.get(\"evals\", []):\n",
    "                knodes = eval_data.get(\"knodes\")  # Nombre de nœuds évalués\n",
    "                depth = eval_data.get(\"depth\")   # Profondeur de recherche\n",
    "                \n",
    "                # Parcoure les variantes principales (principal variations)\n",
    "                for pv in eval_data.get(\"pvs\", []):\n",
    "                    cp = pv.get(\"cp\")       # Score centipawn\n",
    "                    mate = pv.get(\"mate\")   # Nombre de coups avant mat (si applicable)\n",
    "                    line = pv.get(\"line\")   # Ligne de coups prévus\n",
    "                    \n",
    "                    # Ajoute les données extraites à la liste\n",
    "                    data.append({\n",
    "                        \"fen\": fen,\n",
    "                        \"knodes\": knodes,\n",
    "                        \"depth\": depth,\n",
    "                        \"cp\": cp,\n",
    "                        \"mate\": mate,\n",
    "                        \"line\": line\n",
    "                    })\n",
    "\n",
    "    # Convertion de la liste de dictionnaires en DataFrame pandas\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_next_move(df):\n",
    "    \"\"\"\n",
    "    Extrait le premier coup de la colonne 'line' et le stocke dans 'best_move_m1'.\n",
    "    \"\"\"\n",
    "    df[\"best_move_m1\"] = df[\"line\"].str.extract(r'(\\S+)', expand=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_predict_V1(df):\n",
    "    \"\"\"\n",
    "    Ajoute la colonne 'best_move_m2' avec le coup le plus fréquent pour chaque position FEN.\n",
    "    \"\"\"\n",
    "    most_popular_moves = (\n",
    "        df.groupby('fen')['best_move_m1']\n",
    "        .agg(lambda x: x.value_counts().idxmax())  # Coup le plus fréquent par groupe FEN\n",
    "        .rename(\"best_move_m2\"))\n",
    "    \n",
    "    df = df.merge(most_popular_moves, on='fen', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_best_predict(df):\n",
    "    \"\"\"\n",
    "    Filtre les meilleures évaluations par position FEN, en priorisant la profondeur maximale et les évaluations de mat.\n",
    "    \"\"\"\n",
    "    filtered_rows = []\n",
    "\n",
    "    # Grouper par position FEN\n",
    "    for fen, group in df.groupby('fen'):\n",
    "        # Étape 1 : Sélectionner les évaluations avec la profondeur maximale\n",
    "        max_depth = group['depth'].max()\n",
    "        best_evals = group[group['depth'] == max_depth]\n",
    "        \n",
    "        # Étape 2 : Priorité à une évaluation de mat si elle existe\n",
    "        if 'mate' in best_evals and best_evals['mate'].notna().any():\n",
    "            best_row = best_evals.loc[best_evals['mate'].idxmin()]\n",
    "        else:\n",
    "            # Sinon, maximiser la valeur `cp`\n",
    "            best_row = best_evals.loc[best_evals['cp'].idxmax()]\n",
    "        \n",
    "        # Ajouter la meilleure évaluation à la liste\n",
    "        filtered_rows.append(best_row)\n",
    "    \n",
    "    # Créer un nouveau DataFrame avec les meilleures évaluations\n",
    "    return pd.DataFrame(filtered_rows).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_usuless_columns(df) :\n",
    "    \"\"\"\n",
    "    Supprime les colonnes inutiles du DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.drop(columns=['line','mate','cp','depth','knodes'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_matrix(fen: str):\n",
    "    \"\"\"\n",
    "    Convertit une position d'échecs en FEN en une matrice 8x8x13.\n",
    "    8*8 pour les cases de l'échequier et *12 pour chaque pieces uniques (6 Blanches et 6 Noires)\n",
    "    \n",
    "    Parameters: \n",
    "        La représentation FEN de la position.\n",
    "    \n",
    "    Returns:\n",
    "        Une matrice numpy 8x8x12 représentant la position.\n",
    "    \"\"\"\n",
    "    board = chess.Board(fen) #  convertit une représentation FEN en un objet manipulable qui contient toutes les informations sur la position d'échecs. Cet objet permet ensuite de travailler directement avec l'échiquier dans le code.\n",
    "    matrix = np.zeros((13, 8, 8))\n",
    "    piece_map = board.piece_map()\n",
    "\n",
    "    # Populate first 12 8x8 boards (where pieces are)\n",
    "    for square, piece in piece_map.items():\n",
    "        row, col = divmod(square, 8)\n",
    "        piece_type = piece.piece_type - 1\n",
    "        piece_color = 0 if piece.color else 6\n",
    "        matrix[piece_type + piece_color, row, col] = 1\n",
    "\n",
    "    # Populate the legal moves board (13th 8x8 board)\n",
    "    legal_moves = board.legal_moves\n",
    "    for move in legal_moves:\n",
    "        to_square = move.to_square\n",
    "        row_to, col_to = divmod(to_square, 8)\n",
    "        matrix[12, row_to, col_to] = 1\n",
    "\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_moves(moves):\n",
    "    \"\"\"\n",
    "        Cette fonction prend une liste de coups d'échecs (sous forme de chaînes) et encode chaque coup unique\n",
    "        sous forme d'un entier unique. Elle retourne également un dictionnaire qui associe chaque coup à son\n",
    "        entier correspondant.\n",
    "    \"\"\"\n",
    "    move_to_int = {move: idx for idx, move in enumerate(set(moves))}\n",
    "    return [move_to_int[move] for move in moves], move_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.B Extraction des données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>knodes</th>\n",
       "      <th>depth</th>\n",
       "      <th>cp</th>\n",
       "      <th>mate</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>200973</td>\n",
       "      <td>39</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>59730</td>\n",
       "      <td>31</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 g7g6 d1c2 h8d8 e2d2 g6f6 a2a3 b7b5 c4a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>59730</td>\n",
       "      <td>31</td>\n",
       "      <td>134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h8d8 d1e1 a6a5 a2a3 b7b5 c4b3 a5a4 b3a2 c6d7 e6h6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fen  knodes  depth     cp  mate  \\\n",
       "0  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -  200973     39   58.0   NaN   \n",
       "1  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32   62.0   NaN   \n",
       "2  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32  151.0   NaN   \n",
       "3  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   59730     31   64.0   NaN   \n",
       "4  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   59730     31  134.0   NaN   \n",
       "\n",
       "                                                line  \n",
       "0  f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3  \n",
       "1  f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1  \n",
       "2  h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2  \n",
       "3  f7g7 e6e2 g7g6 d1c2 h8d8 e2d2 g6f6 a2a3 b7b5 c4a2  \n",
       "4  h8d8 d1e1 a6a5 a2a3 b7b5 c4b3 a5a4 b3a2 c6d7 e6h6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data\\lichess_db_eval.jsonl'\n",
    "max_rows = 10000000\n",
    "\n",
    "data_raw = extract_data(file_path, max_rows)\n",
    "data_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après extraction nous nous retrouvons avec un dataframe où chaque ligne represente une evaluation d'une certaine poistion, ainsi que **5 variables** associés : \n",
    "\n",
    "| Variable            | Description                                                                                                        |\n",
    "|-----------------|--------------------------------------------------------------------------------------------------------------------|\n",
    "| **knodes**      | Nombre de milliers de nœuds analysés par stockfish pendant la recherche de la position.                   |\n",
    "| **depth**       | Profondeur de la recherche, indiquant le nombre de coups (ou niveaux) explorés par le moteur.                     |\n",
    "| **cp**          | Évaluation en centipions, représentant un avantage matériel en fonction du côté actif (positif pour Blancs, négatif pour Noirs). |\n",
    "| **mate**        | Évaluation de mat. Si une valeur est donnée, elle indique le nombre de coups restants avant que le mat soit atteint. |\n",
    "| **line**        | Ligne (parfois appelée variante) désigne une séquence de coups qui découle d'une position donnée. Elle représente une possible continuation du jeu |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.B Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stockfish utilise différents parametre dans ses algorythmes, notamment le **nombre de noeuf (knodes)** et le la **profondeur (depth)**. En fonction de ces différents parametres, stockfish calcul le **centipions (cp)** et **l'évaluation du mate (mate)**.  \n",
    "\n",
    "Après ces évaluations, stockfish peut alors parfois prédire des coups différents pour une même position, on appelle cela des **variantes**. Certains joueurs vont être plus a l'aise dans une variante plûtot qu'une autre en fonction de leurs styles de jeu, mais pour notre IA cela n'as pas d'importance. Il est alors plus opportun pour notre jeu de donnée de ne garder\n",
    "\n",
    "Nous pouvons alors utiliser 2 méthodes pour garder la meilleur variante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Méthode N°1 : Analyse des Parametres et de l'Evaluation**\n",
    "   1. **Profondeur de recherche (depth)** : Plus la profondeur est grande, plus l'analyse est précise. Priorisations des évaluations avec la profondeur maximale.\n",
    "\n",
    "   2. **Centipions (cp) ou mat (mate)** : Si une évaluation donne un **mate**, elle est prioritaire, car un mat forcé est absolu. En absence de **mate**, choix d'évaluation avec la valeur **cp** la plus élevée pour le joueur actif\n",
    "\n",
    "   3. **Nombre de nœuds analysés (knodes)** : Si plusieurs évaluations ont la même profondeur, celle ayant exploré le plus grand nombre de nœuds est théoriquement plus fiable.\n",
    "\n",
    "   4. **En cas d'égalité parfaite**: En cas d’égalité sur les autres critères, utilisez une évaluation arbitraire.\n",
    "\n",
    "### **Méthode N°2 : Coup le Plus Populaire** \n",
    "blablablabla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création d'une variable `best_move_m1`, qui extrait le prochain coup a jouer, c'est a dire le premier coup de la ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>knodes</th>\n",
       "      <th>depth</th>\n",
       "      <th>cp</th>\n",
       "      <th>mate</th>\n",
       "      <th>line</th>\n",
       "      <th>best_move_m1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>200973</td>\n",
       "      <td>39</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3</td>\n",
       "      <td>f7g7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1</td>\n",
       "      <td>f7g7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2</td>\n",
       "      <td>h8d8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fen  knodes  depth     cp  mate  \\\n",
       "0  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -  200973     39   58.0   NaN   \n",
       "1  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32   62.0   NaN   \n",
       "2  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32  151.0   NaN   \n",
       "\n",
       "                                                line best_move_m1  \n",
       "0  f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3         f7g7  \n",
       "1  f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1         f7g7  \n",
       "2  h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2         h8d8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_V1 = extract_next_move(data_raw)\n",
    "data_V1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création d'une variable `best_move_m2` avec le coup le plus populaire par position en suivant la Méthode N°2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>knodes</th>\n",
       "      <th>depth</th>\n",
       "      <th>cp</th>\n",
       "      <th>mate</th>\n",
       "      <th>line</th>\n",
       "      <th>best_move_m1</th>\n",
       "      <th>best_move_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>200973</td>\n",
       "      <td>39</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3</td>\n",
       "      <td>f7g7</td>\n",
       "      <td>f7g7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1</td>\n",
       "      <td>f7g7</td>\n",
       "      <td>f7g7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2</td>\n",
       "      <td>h8d8</td>\n",
       "      <td>f7g7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fen  knodes  depth     cp  mate  \\\n",
       "0  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -  200973     39   58.0   NaN   \n",
       "1  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32   62.0   NaN   \n",
       "2  7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32  151.0   NaN   \n",
       "\n",
       "                                                line best_move_m1 best_move_m2  \n",
       "0  f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3         f7g7         f7g7  \n",
       "1  f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1         f7g7         f7g7  \n",
       "2  h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2         h8d8         f7g7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_V2 = most_popular_predict_V1(data_V1)\n",
    "data_V2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtrage des lignes pour ne garder qu'une evaluation par position selon la méthode N°1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>knodes</th>\n",
       "      <th>depth</th>\n",
       "      <th>cp</th>\n",
       "      <th>mate</th>\n",
       "      <th>line</th>\n",
       "      <th>best_move_m1</th>\n",
       "      <th>best_move_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1K6/1P4p1/2n4k/p6p/8/8/8/8 w - -</td>\n",
       "      <td>159161</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>b8a8 a5a4 b7b8b c6b8 a8b8 a4a3 b8c8 a3a2 c8d7 ...</td>\n",
       "      <td>b8a8</td>\n",
       "      <td>b8c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1K6/1P4p1/7k/p3n2p/8/8/8/8 b - -</td>\n",
       "      <td>186187</td>\n",
       "      <td>25</td>\n",
       "      <td>460.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e5c6 b8c7 c6b4 c7b6 b4d5 b6c6 d5b4 c6b5 h6g5 b...</td>\n",
       "      <td>e5c6</td>\n",
       "      <td>e5c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1K6/2Pk4/b7/5ppp/8/p5P1/4PP1P/B7 w - -</td>\n",
       "      <td>1472</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e2e3 a3a2 a1c3 a6c8 f2f3 g5g4 f3g4 h5g4 c3d4 c8a6</td>\n",
       "      <td>e2e3</td>\n",
       "      <td>e2e3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fen  knodes  depth     cp  mate  \\\n",
       "0        1K6/1P4p1/2n4k/p6p/8/8/8/8 w - -  159161     29    NaN -12.0   \n",
       "1        1K6/1P4p1/7k/p3n2p/8/8/8/8 b - -  186187     25  460.0   NaN   \n",
       "2  1K6/2Pk4/b7/5ppp/8/p5P1/4PP1P/B7 w - -    1472     39    0.0   NaN   \n",
       "\n",
       "                                                line best_move_m1 best_move_m2  \n",
       "0  b8a8 a5a4 b7b8b c6b8 a8b8 a4a3 b8c8 a3a2 c8d7 ...         b8a8         b8c8  \n",
       "1  e5c6 b8c7 c6b4 c7b6 b4d5 b6c6 d5b4 c6b5 h6g5 b...         e5c6         e5c6  \n",
       "2  e2e3 a3a2 a1c3 a6c8 f2f3 g5g4 f3g4 h5g4 c3d4 c8a6         e2e3         e2e3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_V3 = filter_best_predict(data_V2)\n",
    "data_V3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppression des variables inutiles. Les variables `knodes`, `depth`, `cp`, `mate` et `line` ne sont plus utile pour la suite du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>best_move_m1</th>\n",
       "      <th>best_move_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1K6/1P4p1/2n4k/p6p/8/8/8/8 w - -</td>\n",
       "      <td>b8a8</td>\n",
       "      <td>b8c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1K6/1P4p1/7k/p3n2p/8/8/8/8 b - -</td>\n",
       "      <td>e5c6</td>\n",
       "      <td>e5c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1K6/2Pk4/b7/5ppp/8/p5P1/4PP1P/B7 w - -</td>\n",
       "      <td>e2e3</td>\n",
       "      <td>e2e3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Kb2n2/2P1k3/2B5/4Bppp/8/p5P1/4PP1P/8 b - -</td>\n",
       "      <td>f8d7</td>\n",
       "      <td>c8e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1Kb5/2PBk3/8/4Bppp/8/p5P1/4PP1P/8 b - -</td>\n",
       "      <td>c8d7</td>\n",
       "      <td>e7d7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           fen best_move_m1 best_move_m2\n",
       "0             1K6/1P4p1/2n4k/p6p/8/8/8/8 w - -         b8a8         b8c8\n",
       "1             1K6/1P4p1/7k/p3n2p/8/8/8/8 b - -         e5c6         e5c6\n",
       "2       1K6/2Pk4/b7/5ppp/8/p5P1/4PP1P/B7 w - -         e2e3         e2e3\n",
       "3  1Kb2n2/2P1k3/2B5/4Bppp/8/p5P1/4PP1P/8 b - -         f8d7         c8e6\n",
       "4      1Kb5/2PBk3/8/4Bppp/8/p5P1/4PP1P/8 b - -         c8d7         e7d7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = drop_usuless_columns(data_V3)\n",
    "data_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sauvegarde des données netoyées en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv('data/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. MODELISATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.A Transformation finale des données :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blablablabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_cleaned.csv' )\n",
    "\n",
    "X = data['fen']\n",
    "y = data['best_move_m1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Traduction des données sous une forme interpretable par le reseau de neurone.\n",
    "  - **Position (Fen)** -> Matrice Numpy\n",
    "  - **Coup a joué (UCI)** -> Encodage de chaque coup distincts (sous forme d'entier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X.apply(fen_to_matrix)\n",
    "X = np.array(X.tolist())\n",
    "\n",
    "# Encode les mouvements et conversion en catégories\n",
    "y, move_to_int = encode_moves(y)\n",
    "y = to_categorical(y, num_classes=len(move_to_int))\n",
    "\n",
    "\n",
    "# Sauvegarde de move_to_int dans un fichier JSON\n",
    "with open('Models/move_int_dico.json', 'w') as file:\n",
    "    json.dump(move_to_int, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.B Définition et entrainement des différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle N°1 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle N°2 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spécifications du modèle 2 :\n",
    "\n",
    "- **Première couche de convolution :** \n",
    "    - *Conv2D(64, (3, 3), activation='relu', input_shape=(13, 8, 8)) :* \n",
    "        - **64** : nombre de filtres (ou noyaux de convolution) utilisés par la couche. \n",
    "        - **(3, 3)** : taille des filtres (matrice 3x3 pour détecter des caractéristiques locales). \n",
    "        - **activation='relu'** : fonction d'activation ReLU (Rectified Linear Unit) qui introduit de la non-linéarité. \n",
    "        - **input_shape=(13, 8, 8)** : forme de l'entrée (par exemple, un tenseur 13x8x8 représentant vos données d'entrée). \n",
    "    - *BatchNormalization():* \n",
    "        - **Normalisation des données en entrée de la couche suivante pour stabiliser et accélérer l'apprentissage.** \n",
    "    - *MaxPooling2D(pool_size=(2, 2)):*  \n",
    "        - **Sous-échantillonnage spatial (réduction de la dimension spatiale).** \n",
    "        - **pool_size=(2, 2) : taille de la fenêtre de pooling (matrice 2x2) qui réduit chaque dimension de moitié.** \n",
    "- **Deuxième couche de convolution :** \n",
    "    - *Conv2D(128, (3, 3), activation='relu') :* \n",
    "        - **128 : nombre de filtres plus élevé pour apprendre des caractéristiques plus complexes.** \n",
    "        - **(3, 3) : taille des filtres.** \n",
    "        - **activation='relu' : même fonction d'activation pour conserver la non-linéarité.** \n",
    "    - *BatchNormalization():* \n",
    "        - **Normalisation des données en entrée de la couche suivante pour stabiliser et accélérer l'apprentissage.** \n",
    "    - *MaxPooling2D(pool_size=(2, 2)):*  \n",
    "        - **Sous-échantillonnage spatial (réduction de la dimension spatiale).** \n",
    "        - **pool_size=(2, 2) : taille de la fenêtre de pooling (matrice 2x2) qui réduit chaque dimension de moitié.** \n",
    "\n",
    "- **Suite des paramètres :** \n",
    "    -  *Flatten() :* \n",
    "        - **Mise à plat des données (passage des données 2D/3D à un vecteur 1D) pour préparer les données pour les couches denses.** \n",
    "    - *Dropout(0.4) :* \n",
    "        - **Régularisation pour réduire le surapprentissage.** \n",
    "        - **0.4 : 40% des neurones sont désactivés pendant l'entraînement.** \n",
    "\n",
    "    - *Dense(256, activation='relu') :* \n",
    "        - **Couche entièrement connectée (dense).** \n",
    "        - **256 : nombre de neurones dans la couche.** \n",
    "        - **activation='relu' : fonction d'activation ReLU pour apprendre des représentations complexes.** \n",
    "\n",
    "    - *Dropout(0.3) :* \n",
    "        - **Dropout supplémentaire, mais avec un taux réduit (30%) pour limiter encore le surapprentissage tout en maintenant les performances.** \n",
    "\n",
    "    - *Dense(len(move_to_int), activation='softmax') :* \n",
    "        - **Couche de sortie entièrement connectée.** \n",
    "        - **len(move_to_int) : nombre de classes possibles dans la tâche de classification (dimension de sortie).** \n",
    "        - **activation='softmax' : fonction d'activation Softmax pour produire des probabilités normalisées pour chaque classe.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Justifications de la spécifications du modèle 2 :\n",
    "\n",
    "-   *1. Entrée du modèle : input_shape=(13, 8, 8) :* \n",
    "    -   La dimension (13, 8, 8) est cohérente avec une représentation d'un échiquier : \\\n",
    "        8x8 représente les cases de l'échiquier. \\\n",
    "        13 couches (ou canaux) permettent de coder les différentes informations nécessaires : \\\n",
    "        Positions des pièces blanches et noires (par exemple, une couche par type de pièce). \n",
    "    -   Informations supplémentaires comme le droit de roquer, la possibilité d'une prise en passant, etc. \\\n",
    "        Cette structuration est standard pour les réseaux convolutifs, car elle tire parti des propriétés spatiales des données. \n",
    "\n",
    "    -   Améliorations possibles : \\\n",
    "        Ajouter plus de dimensions pertinentes si nécessaire, comme un historique des coups pour aider à prédire les intentions stratégiques.\n",
    "\n",
    "-   *2. Couche de convolution : Conv2D :*\n",
    "    -   Les couches convolutives sont bien adaptées pour : \\\n",
    "        Identifier des motifs locaux, comme des alignements de pièces ou des attaques potentielles.\\\n",
    "        Exploiter la structure spatiale de l'échiquier.\n",
    "\n",
    "    -   Paramètres des couches convolutives : \\\n",
    "        64 filtres (1ère couche) et 128 filtres (2ème couche) : \\\n",
    "        Permettent d'extraire des motifs simples dans les premières couches (par exemple, relations entre deux pièces) et des motifs plus complexes dans les couches profondes (comme des schémas stratégiques sur une partie de l'échiquier). \n",
    "    -   Taille des filtres (3, 3) : \\\n",
    "        Taille standard pour détecter des relations entre pièces sur des zones locales de l'échiquier. \\\n",
    "        Peut être adapté pour capturer plus de contexte (par exemple, (5, 5) pourrait identifier des structures plus globales comme un réseau de défense).\n",
    "\n",
    "-   *3. Batch Normalization :* \n",
    "    - Stabilise l'entraînement du réseau et permet des mises à jour de poids plus efficaces. \\\n",
    "    Crucial pour des architectures profondes où des déséquilibres d'échelle dans les activations pourraient ralentir l'apprentissage.\n",
    "\n",
    "-   *4. MaxPooling2D :*\n",
    "    -   Utilité : \\\n",
    "    Réduit les dimensions spatiales, ce qui permet de capturer des relations globales en résumant des zones locales de l'échiquier.\n",
    "    Le pooling successif peut, cependant, entraîner une perte de précision sur les positions exactes des pièces.\n",
    "\n",
    "    - Limites potentielles : \\\n",
    "    Les échecs nécessitent souvent une localisation précise des pièces (un cavalier ou une reine mal positionné peut changer complètement le sens d'un coup).\\\n",
    "    L’utilisation de techniques comme strided convolutions ou une réduction de la profondeur de pooling pourrait éviter cette perte de précision.\n",
    "\n",
    "-   *5. Flatten :*\n",
    "    - Après les couches convolutives, les données 2D (spatiales) sont aplaties en un vecteur 1D pour permettre des connexions avec les couches entièrement connectées. \n",
    "    - Cela combine toutes les caractéristiques extraites par les convolutions en un ensemble global.\n",
    "\n",
    "-   *6. Dropout :*\n",
    "    - Évite le surapprentissage, ce qui est crucial pour généraliser sur des positions d'échiquier variées et imprévues. \\\n",
    "    Les taux de 0.4 (40%) et 0.3 (30%) sont raisonnables : \\\n",
    "    Éviter de surcharger le modèle tout en maintenant une capacité suffisante pour apprendre des motifs complexes.\n",
    "\n",
    "    - Limites : \\\n",
    "    Pour une IA jouant aux échecs, une approche comme l'entraînement régularisé combiné à des données augmentées (positions générées à partir de parties réelles ou simulées) pourrait être encore plus efficace.\n",
    "\n",
    "-   *7. Dense Layers :*\n",
    "    - 256 neurones (1ère couche dense) : \\\n",
    "    Permet d'apprendre des représentations abstraites globales du plateau après les convolutions.\\\n",
    "    Bon compromis entre la capacité d'apprentissage et la régularisation.\\\n",
    "    Couche de sortie : Dense(len(move_to_int), activation='softmax')\n",
    "\n",
    "    - len(move_to_int) : \\\n",
    "    Correspond au nombre total de coups possibles dans une position d'échecs. Cela inclut les coups valides et les promotions.\n",
    "\n",
    "    - Activation softmax : \\\n",
    "    Transforme les scores en probabilités normalisées. \\\n",
    "    Utile pour choisir le coup avec la plus forte probabilité comme sortie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisations proposées par l'IA pour des echecs avancés\n",
    "\n",
    "- **Renforcement des convolutions globales :**\n",
    "    - Ajouter des couches convolutionnelles avec des filtres plus larges ou des architectures comme ResNet ou attention mechanisms (transformers) pour capturer des relations complexes à long terme sur l'échiquier.\n",
    "\n",
    "- **Traitement séquentiel :**\n",
    "    - Les échecs sont séquentiels par nature. Enrichir le modèle avec des approches séquentielles (par exemple, LSTM ou Transformer) pour capturer l'historique des coups.\n",
    "\n",
    "- **Données massives :**\n",
    "    - Entraîner sur un grand corpus de parties (par exemple, des parties de maîtres ou générées par un moteur) pour couvrir la complexité stratégique.\n",
    "\n",
    "- **Search Algorithms (Monte Carlo Tree Search) :**\n",
    "    - Le modèle pourrait prédire des probabilités initiales pour guider un algorithme de recherche d'arbre (comme le fait AlphaZero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1927</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">495,239</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m4,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m0\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m0\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m0\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1927\u001b[0m)           │       \u001b[38;5;34m495,239\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">574,791</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m574,791\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">574,407</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m574,407\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2 = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(13, 8, 8)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)), \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.4),  \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),  \n",
    "    Dense(len(move_to_int), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation du modèle avec un optimiseur personnalisé, une fonction de perte et des métriques.\n",
    "\n",
    "- *model_2.compile(optimizer=Adam(learning_rate=1e-4) :*  \n",
    "    - Optimiseur utilisé pour ajuster les poids du modèle.\n",
    "    - Adam : un optimiseur efficace combinant les avantages d'Adagrad et RMSProp.\n",
    "    - learning_rate=1e-4 : taux d'apprentissage (0.0001) contrôle la vitesse à laquelle l'optimiseur ajuste les poids.\n",
    "    - Un learning rate bas favorise un apprentissage stable mais peut être plus lent.\n",
    "- *loss='categorical_crossentropy' :*\n",
    "    - Fonction de perte utilisée pour mesurer l'écart entre les prédictions du modèle et les véritables étiquettes.\n",
    "    - 'categorical_crossentropy' : utilisée pour des problèmes de classification multi-classe où les étiquettes sont représentées sous forme one-hot.\n",
    "- *metrics=['accuracy'] :*\n",
    "    - Liste des métriques à suivre pendant l'entraînement et l'évaluation.\n",
    "    - 'accuracy' : proportion de prédictions correctes, utile pour évaluer les performances globales du modèle.\n",
    ")\n",
    "\n",
    "\n",
    "#### Justification de l'utilisation de la fonction de compilation\n",
    "\n",
    "Cette fonction de compilation sert à configurer les aspects fondamentaux de l’entraînement du modèle dans le cadre de la création d’une IA jouant aux échecs de manière avancée. Voici un décryptage de ses éléments dans ce contexte particulier :\n",
    "\n",
    "-   *1. Optimiseur : Adam(learning_rate=1e-4):*\n",
    "\n",
    "    - Rôle dans une IA d'échecs : \\\n",
    "    Ajuste les poids du modèle pour minimiser la perte pendant l’entraînement.\n",
    "    \n",
    "    - Pourquoi Adam ? \\\n",
    "    Adam combine les avantages de RMSProp (adapte dynamiquement le taux d'apprentissage pour chaque poids) et momentum (accélère l'apprentissage en zones de faible gradient). \\\n",
    "    Convient aux architectures complexes comme celles utilisées ici, en garantissant une convergence rapide et efficace.\\\n",
    "\n",
    "    - Pourquoi un learning rate de 1e-4 ? \\\n",
    "    Aux échecs, les motifs et stratégies peuvent être complexes et subtils. \\\n",
    "    Un learning rate bas (0.0001) permet un ajustement progressif, réduisant le risque de sauter des minima locaux ou d'osciller autour d’une solution optimale.\\\n",
    "    Ce choix est crucial pour capturer des relations stratégiques délicates, comme les sacrifices ou les plans à long terme.\n",
    "\n",
    "-   *2. Fonction de perte : categorical_crossentropy:*\n",
    "    -   Rôle dans une IA d'échecs : \\\n",
    "    Mesure la différence entre les prédictions du modèle et la vérité terrain.\n",
    "\n",
    "    - Pourquoi categorical_crossentropy ? \\\n",
    "    Les échecs sont un problème de classification multi-classe : pour chaque position donnée, le modèle doit prédire un coup parmi un ensemble de coups possibles. \\\n",
    "    Les étiquettes (coups possibles) sont souvent représentées sous forme one-hot : \n",
    "        - Exemple : Si un coup spécifique est correct, sa probabilité dans le vecteur de sortie est 1, et les autres sont 0. \\\n",
    "        La perte categorical_crossentropy punit les prédictions qui s’écartent de la probabilité correcte, forçant le modèle à se concentrer sur les coups les plus plausibles.\n",
    "\n",
    "-   *3. Métrique : accuracy :*\n",
    "    - Rôle dans une IA d'échecs : \\\n",
    "    Suit la proportion de coups prédits correctement.\n",
    "\n",
    "    - Pourquoi utiliser l'accuracy ? \\\n",
    "    Permet de mesurer si le modèle est capable de reproduire les coups attendus pour des positions données, comme dans des parties annotées ou simulées. \\\n",
    "    Cela donne une indication globale des performances du modèle pendant l’entraînement.\n",
    "\n",
    "    - Limitation de l’accuracy : \\\n",
    "    Aux échecs, il peut y avoir plusieurs coups corrects dans une position donnée (par exemple, coups équivalents ou différents plans stratégiques). \\\n",
    "    Une simple mesure d’accuracy ne capture pas toujours cette diversité.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisations proposées par l'IA pour des échecs avancés.\n",
    "\n",
    "-   Introduire d'autres métriques comme :\n",
    "    - \"Top-K accuracy\" : Mesure si le coup correct est parmi les K meilleurs coups prédits.\n",
    "    - \"Evaluation score accuracy\" : Mesure l'alignement du modèle avec les évaluations de moteurs d'échecs (par exemple, Stockfish).\n",
    "\n",
    "- Fonction de perte personnalisée :\n",
    "    - Une fonction de perte qui prend en compte la qualité des coups (par exemple, les évaluations du moteur) pourrait être plus adaptée qu’une simple catégorisation.\n",
    "\n",
    "- Renforcement :\n",
    "    - Une IA d’échecs avancée comme AlphaZero remplace progressivement les approches purement supervisées (comme ici) par des approches de renforcement profond, où le modèle apprend directement à maximiser ses chances de gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_2.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),  \n",
    "    loss='categorical_crossentropy',  \n",
    "    metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrainement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(X, y, epochs=25, validation_split=0.1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modèle N°3** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. EVALUATION**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROJETMLMARGAUX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
