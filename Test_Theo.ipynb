{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. BILBIOTHEQUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. EXTRACTION DES DONNEES BRUTES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les données depuis le JSONL\n",
    "def extract_data(file_path, max_rows=50):\n",
    "    data = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            if idx >= max_rows:\n",
    "                break\n",
    "\n",
    "            position = json.loads(line)\n",
    "            fen = position.get(\"fen\")\n",
    "\n",
    "            for eval_data in position.get(\"evals\", []):\n",
    "                knodes = eval_data.get(\"knodes\")\n",
    "                depth = eval_data.get(\"depth\")\n",
    "                \n",
    "                for pv in eval_data.get(\"pvs\", []):\n",
    "                    cp = pv.get(\"cp\")\n",
    "                    mate = pv.get(\"mate\")\n",
    "                    line = pv.get(\"line\")\n",
    "\n",
    "                    data.append({\n",
    "                        \"fen\": fen,\n",
    "                        \"knodes\": knodes,\n",
    "                        \"depth\": depth,\n",
    "                        \"cp\": cp,\n",
    "                        \"mate\": mate,\n",
    "                        \"line\": line\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>knodes</th>\n",
       "      <th>depth</th>\n",
       "      <th>cp</th>\n",
       "      <th>mate</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>200973</td>\n",
       "      <td>39</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>71927</td>\n",
       "      <td>32</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>59730</td>\n",
       "      <td>31</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f7g7 e6e2 g7g6 d1c2 h8d8 e2d2 g6f6 a2a3 b7b5 c4a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -</td>\n",
       "      <td>59730</td>\n",
       "      <td>31</td>\n",
       "      <td>134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h8d8 d1e1 a6a5 a2a3 b7b5 c4b3 a5a4 b3a2 c6d7 e6h6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330094</th>\n",
       "      <td>4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...</td>\n",
       "      <td>6342</td>\n",
       "      <td>20</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e2e3 b5b3 a4a7 g7e5 c7h7 e8a8 a7d7 b3b2 h7e7 e5g3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330095</th>\n",
       "      <td>4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...</td>\n",
       "      <td>6342</td>\n",
       "      <td>20</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b3b4 e8b8 c7d7 b5b4 a4a7 g7d4 a7c7 d6d5 d7e7 b4b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330096</th>\n",
       "      <td>4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...</td>\n",
       "      <td>6342</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a4a3 g7b2 a3a7 b2d4 a7a4 d4b6 c7d7 b5b3 a4a6 b6c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330097</th>\n",
       "      <td>4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...</td>\n",
       "      <td>6342</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a4a7 g7d4 a7a4 d4b6 c7d7 b5b3 a4a6 b6c5 a6c6 b3c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330098</th>\n",
       "      <td>4k3/6Q1/5K2/8/8/8/8/4r3 w - -</td>\n",
       "      <td>6355</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>g7g3 e1e2 g3g4 e2f2 f6e6 e8d8 g4d4 d8c7 d4f2 c7c6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2330099 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       fen  knodes  depth  \\\n",
       "0             7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -  200973     39   \n",
       "1             7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32   \n",
       "2             7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   71927     32   \n",
       "3             7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   59730     31   \n",
       "4             7r/1p3k2/p1bPR3/5p2/2B2P1p/8/PP4P1/3K4 b - -   59730     31   \n",
       "...                                                    ...     ...    ...   \n",
       "2330094  4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...    6342     20   \n",
       "2330095  4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...    6342     20   \n",
       "2330096  4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...    6342     20   \n",
       "2330097  4r1k1/2R3b1/3pp1p1/1r3pBp/R6P/1P4P1/4PP2/6K1 w...    6342     20   \n",
       "2330098                      4k3/6Q1/5K2/8/8/8/8/4r3 w - -    6355     53   \n",
       "\n",
       "            cp  mate                                               line  \n",
       "0         58.0   NaN  f7g7 e6e2 h8d8 e2d2 b7b5 c4e6 g7f6 e6b3 a6a5 a2a3  \n",
       "1         62.0   NaN  f7g7 e6e2 b7b5 c4b3 h8d8 e2d2 a6a5 a2a3 g7f6 d1e1  \n",
       "2        151.0   NaN  h8d8 d1e1 a6a5 a2a3 b7b5 c4a2 c6d7 e6e7 f7g6 e1f2  \n",
       "3         64.0   NaN  f7g7 e6e2 g7g6 d1c2 h8d8 e2d2 g6f6 a2a3 b7b5 c4a2  \n",
       "4        134.0   NaN  h8d8 d1e1 a6a5 a2a3 b7b5 c4b3 a5a4 b3a2 c6d7 e6h6  \n",
       "...        ...   ...                                                ...  \n",
       "2330094   54.0   NaN  e2e3 b5b3 a4a7 g7e5 c7h7 e8a8 a7d7 b3b2 h7e7 e5g3  \n",
       "2330095   42.0   NaN  b3b4 e8b8 c7d7 b5b4 a4a7 g7d4 a7c7 d6d5 d7e7 b4b6  \n",
       "2330096   35.0   NaN  a4a3 g7b2 a3a7 b2d4 a7a4 d4b6 c7d7 b5b3 a4a6 b6c5  \n",
       "2330097   35.0   NaN  a4a7 g7d4 a7a4 d4b6 c7d7 b5b3 a4a6 b6c5 a6c6 b3c3  \n",
       "2330098    NaN  10.0  g7g3 e1e2 g3g4 e2f2 f6e6 e8d8 g4d4 d8c7 d4f2 c7c6  \n",
       "\n",
       "[2330099 rows x 6 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilisation de la fonction\n",
    "file_path = 'data\\lichess_db_eval.jsonl'  # Remplacez par le chemin de votre fichier\n",
    "data_raw = extract_data(file_path, max_rows=500000)\n",
    "data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type            | Description                                                                                                        |\n",
    "|-----------------|--------------------------------------------------------------------------------------------------------------------|\n",
    "| **knodes**      | Nombre de milliers de nœuds analysés par stockfish pendant la recherche de la position.                   |\n",
    "| **depth**       | Profondeur de la recherche, indiquant le nombre de coups (ou niveaux) explorés par le moteur.                     |\n",
    "| **cp**          | Évaluation en centipions, représentant un avantage matériel en fonction du côté actif (positif pour Blancs, négatif pour Noirs). |\n",
    "| **mate**        | Évaluation de mat. Si une valeur est donnée, elle indique le nombre de coups restants avant que le mat soit atteint. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. ML ENGEENERING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Analyse des Variantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stockfish utilie différents parametre dans son algorythme, notamment le **nombre de noeuf (knodes)** et le la **profondeur (depth)**. En fonction de ces différents parametres, stockfish calcul le **centipions (cp)** et **l'évaluation du mate (mate)**.  \n",
    "\n",
    "Après ces évaluations, stockfish peut alors parfois prédire des coups différents pour une même position, on appelle cela des **variantes**. Ces coups sont différents mais ont un impacte similaire ou quasi-similaire sur l'avantage qu'il donne a celui qui le joue (en terme d'evaluation de la position). \n",
    "\n",
    "Certains joueurs vont être plus a l'aise dans une variante plûtot qu'une autre en fonction de leurs styles de jeu ou de leurs connaissances, mais pour une IA cela n'as pas d'importance ! Toutefois, notre source de donnée nous propose plusieurs analyse de stockfish pour chaques position, apportant son lot de variante.\n",
    "\n",
    "Nous pouvons alors utiliser 2 méthodes pour garder la meilleur variante :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Méthode 1 : Analyse des Parametres et de l'Evaluation** \n",
    "   1. **Profondeur de recherche (depth)** :\n",
    "      - Plus la profondeur est grande, plus l'analyse est précise.\n",
    "      - Priorisez les évaluations avec la profondeur maximale atteinte.\n",
    "\n",
    "   2. **Centipions (cp) ou mat (mate)** :\n",
    "      - Si une évaluation donne un **mate**, elle est prioritaire, car un mat forcé est absolu.\n",
    "      - En absence de **mate**, choix d'évaluation avec la valeur **cp** la plus élevée pour le joueur actif\n",
    "\n",
    "   3. **Nombre de nœuds analysés (knodes)** :\n",
    "      - Si plusieurs évaluations ont la même profondeur, celle ayant exploré le plus grand nombre de nœuds est théoriquement plus fiable.\n",
    "\n",
    "   4. **En cas d'égalité parfaite**:\n",
    "      - En cas d’égalité sur les autres critères, utilisez une évaluation arbitraire.\n",
    "\n",
    "### **Méthode 2 : Coup le Plus Populaire** \n",
    "blablablabla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrait le premier coup de la ligne (donc le prochain coup a jouer) pour en créer une variable a part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_next_moove(df) :\n",
    "    # Extraction du premier groupe de mots de la colonne 'line'\n",
    "    df[\"analysed_best_move\"] = df[\"line\"].str.extract(r'(\\S+)', expand=False)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la variable du le coup le plus cité dans les prédictions d'une même position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_predict_V1(df):\n",
    "    most_popular_moves = (\n",
    "        df.groupby('fen')['analysed_best_move']\n",
    "        .agg(lambda x: x.value_counts().idxmax())  # Trouver le coup le plus fréquent\n",
    "        .rename(\"most_popular_move_of_the_category\")\n",
    "    )\n",
    "\n",
    "    # Ajouter cette information dans le DataFrame original\n",
    "    df = df.merge(most_popular_moves, on='fen', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne garde que la ligne avec les critères d'évualiations les plus hauts et les parametres d'analyse de stockfish les plus \"pousser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_best_predict(df):\n",
    "    filtered_rows = []\n",
    "\n",
    "    # Grouper par position FEN\n",
    "    for fen, group in df.groupby('fen'):\n",
    "        # Étape 1 : Sélectionner les évaluations avec la profondeur maximale\n",
    "        max_depth = group['depth'].max()\n",
    "        best_evals = group[group['depth'] == max_depth]\n",
    "        \n",
    "        # Étape 2 : Priorité à une évaluation de mat si elle existe\n",
    "        if 'mate' in best_evals and best_evals['mate'].notna().any():\n",
    "            best_row = best_evals.loc[best_evals['mate'].idxmin()]\n",
    "        else:\n",
    "            # Sinon, maximiser la valeur `cp`\n",
    "            best_row = best_evals.loc[best_evals['cp'].idxmax()]\n",
    "        \n",
    "        # Ajouter la meilleure évaluation à la liste\n",
    "        filtered_rows.append(best_row)\n",
    "    \n",
    "    # Créer un nouveau DataFrame avec les meilleures évaluations\n",
    "    return pd.DataFrame(filtered_rows).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprime les colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_usuless_columns(df) :\n",
    "    df = df.drop(columns=['line','mate','cp','depth','knodes'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>analysed_best_move</th>\n",
       "      <th>most_popular_move_of_the_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1B1b4/8/2pP2p1/5p2/k7/8/5PK1/8 b - -</td>\n",
       "      <td>d8b6</td>\n",
       "      <td>d8b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1B1k3r/p4ppp/5n2/2p1N3/1P6/8/P1P2PbP/2K1R3 b - -</td>\n",
       "      <td>g2d5</td>\n",
       "      <td>h8e8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1B1k4/2P2pp1/7p/1n6/8/7P/5PP1/5K2 b - -</td>\n",
       "      <td>d8e8</td>\n",
       "      <td>b5c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1B1k4/2n2pp1/7p/8/8/7P/5PP1/5K2 w - -</td>\n",
       "      <td>b8c7</td>\n",
       "      <td>b8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1B1k4/5pp1/2P4p/1n6/8/7P/5PP1/5K2 w - -</td>\n",
       "      <td>h3h4</td>\n",
       "      <td>h3h4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>rrrrkrrr/ppp1p1pp/8/5p2/4P3/5P2/PPP3PP/RRRRKRR...</td>\n",
       "      <td>d8d6</td>\n",
       "      <td>d8d6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>rrrrkrrr/ppppp1pp/8/5p2/4P3/3P4/PPP2PPP/RRRRKR...</td>\n",
       "      <td>d7d5</td>\n",
       "      <td>d7d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>rrrrkrrr/ppppp1pp/8/5p2/8/3P4/PPP1PPPP/RRRRKRR...</td>\n",
       "      <td>f2f4</td>\n",
       "      <td>f2f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>rrrrkrrr/pppppppp/8/8/8/3P4/PPP1PPPP/RRRRKRRR ...</td>\n",
       "      <td>f7f5</td>\n",
       "      <td>f7f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>rrrrkrrr/pppppppp/8/8/8/8/PPPPPPPP/RRRRKRRR w ...</td>\n",
       "      <td>g2g4</td>\n",
       "      <td>g2g4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      fen analysed_best_move  \\\n",
       "0                    1B1b4/8/2pP2p1/5p2/k7/8/5PK1/8 b - -               d8b6   \n",
       "1        1B1k3r/p4ppp/5n2/2p1N3/1P6/8/P1P2PbP/2K1R3 b - -               g2d5   \n",
       "2                 1B1k4/2P2pp1/7p/1n6/8/7P/5PP1/5K2 b - -               d8e8   \n",
       "3                   1B1k4/2n2pp1/7p/8/8/7P/5PP1/5K2 w - -               b8c7   \n",
       "4                 1B1k4/5pp1/2P4p/1n6/8/7P/5PP1/5K2 w - -               h3h4   \n",
       "...                                                   ...                ...   \n",
       "499995  rrrrkrrr/ppp1p1pp/8/5p2/4P3/5P2/PPP3PP/RRRRKRR...               d8d6   \n",
       "499996  rrrrkrrr/ppppp1pp/8/5p2/4P3/3P4/PPP2PPP/RRRRKR...               d7d5   \n",
       "499997  rrrrkrrr/ppppp1pp/8/5p2/8/3P4/PPP1PPPP/RRRRKRR...               f2f4   \n",
       "499998  rrrrkrrr/pppppppp/8/8/8/3P4/PPP1PPPP/RRRRKRRR ...               f7f5   \n",
       "499999  rrrrkrrr/pppppppp/8/8/8/8/PPPPPPPP/RRRRKRRR w ...               g2g4   \n",
       "\n",
       "       most_popular_move_of_the_category  \n",
       "0                                   d8b6  \n",
       "1                                   h8e8  \n",
       "2                                   b5c7  \n",
       "3                                   b8c7  \n",
       "4                                   h3h4  \n",
       "...                                  ...  \n",
       "499995                              d8d6  \n",
       "499996                              d7d5  \n",
       "499997                              f2f4  \n",
       "499998                              f7f5  \n",
       "499999                              g2g4  \n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned_V1 = extract_next_moove(data_raw)\n",
    "data_cleaned_V1 = most_popular_predict_V1(data_cleaned_V1)\n",
    "data_cleaned_V1 = filter_best_predict(data_cleaned_V1)\n",
    "data_cleaned_V1 = drop_usuless_columns(data_cleaned_V1)\n",
    "data_cleaned_V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export des Données Netoyées en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_V1.to_csv('data/data_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
